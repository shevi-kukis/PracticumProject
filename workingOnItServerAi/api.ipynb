{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.100:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Mar/2025 16:32:37] \"OPTIONS /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:32:50] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:32:58] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:01] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:04] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:04] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:08] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:11] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:15] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:18] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:21] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:21] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:25] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:29] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:29] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:32] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:36] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:36] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:37] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:40] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:42] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:46] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:48] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:50] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:52] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:53] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:56] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:57] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:33:59] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:03] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:03] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:04] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:08] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:09] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:11] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:13] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:15] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:17] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:19] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:20] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:23] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:24] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:28] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:31] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:33] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "[2025-03-25 16:34:34,872] ERROR in app: Exception on /check_answer [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 136, in check_answer\n",
      "    feedback = check_answer_with_gamini(question, answer)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 89, in check_answer_with_gamini\n",
      "    for chunk in client.models.generate_content_stream(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 5507, in generate_content_stream\n",
      "    for chunk in response:\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 4409, in _generate_content_stream\n",
      "    for response_dict in self._api_client.request_streamed(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 659, in request_streamed\n",
      "    session_response = self._request(http_request, stream=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 557, in _request\n",
      "    errors.APIError.raise_for_response(response)\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\errors.py\", line 106, in raise_for_response\n",
      "    raise ClientError(status_code, response)\n",
      "google.genai.errors.ClientError: 429 Too Many Requests. {'message': 'Response not read', 'status': 'Too Many Requests'}\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:35] \"POST /check_answer HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:41] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:44] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:47] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:48] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:50] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:54] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:55] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:34:59] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:02] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:02] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:05] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:08] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:10] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:10] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:15] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:15] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:16] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:19] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:23] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:23] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:27] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:27] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:31] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:33] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "[2025-03-25 16:35:35,544] ERROR in app: Exception on /check_answer [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 136, in check_answer\n",
      "    feedback = check_answer_with_gamini(question, answer)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 89, in check_answer_with_gamini\n",
      "    for chunk in client.models.generate_content_stream(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 5507, in generate_content_stream\n",
      "    for chunk in response:\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 4409, in _generate_content_stream\n",
      "    for response_dict in self._api_client.request_streamed(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 659, in request_streamed\n",
      "    session_response = self._request(http_request, stream=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 557, in _request\n",
      "    errors.APIError.raise_for_response(response)\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\errors.py\", line 106, in raise_for_response\n",
      "    raise ClientError(status_code, response)\n",
      "google.genai.errors.ClientError: 429 Too Many Requests. {'message': 'Response not read', 'status': 'Too Many Requests'}\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:35] \"POST /check_answer HTTP/1.1\" 500 -\n",
      "[2025-03-25 16:35:39,062] ERROR in app: Exception on /check_answer [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 136, in check_answer\n",
      "    feedback = check_answer_with_gamini(question, answer)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 89, in check_answer_with_gamini\n",
      "    for chunk in client.models.generate_content_stream(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 5507, in generate_content_stream\n",
      "    for chunk in response:\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 4409, in _generate_content_stream\n",
      "    for response_dict in self._api_client.request_streamed(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 659, in request_streamed\n",
      "    session_response = self._request(http_request, stream=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 557, in _request\n",
      "    errors.APIError.raise_for_response(response)\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\errors.py\", line 106, in raise_for_response\n",
      "    raise ClientError(status_code, response)\n",
      "google.genai.errors.ClientError: 429 Too Many Requests. {'message': 'Response not read', 'status': 'Too Many Requests'}\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:39] \"POST /check_answer HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:40] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:46] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:46] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:49] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:50] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:53] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:54] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:35:57] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:01] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:15] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:18] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:20] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:22] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:23] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:26] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:28] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:31] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:34] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:36] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:38] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:41] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:41] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:44] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:44] \"OPTIONS /evaluate_responses HTTP/1.1\" 200 -\n",
      "[2025-03-25 16:36:46,787] ERROR in app: Exception on /evaluate_responses [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 201, in evaluate_responses\n",
      "    average_score, summary = evaluate_feedback(feedback_list)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 148, in evaluate_feedback\n",
      "    score = extract_score(feedback)  # פונקציה שתשאב את הציון מהפידבק\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 185, in extract_score\n",
      "    score = feedback_json.get(\"score\", 0)  # קבלת הערך של \"score\" או 0 אם הוא לא קיים\n",
      "            ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'list' object has no attribute 'get'\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:46] \"POST /evaluate_responses HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:47] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:56] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:59] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:36:59] \"OPTIONS /evaluate_responses HTTP/1.1\" 200 -\n",
      "[2025-03-25 16:37:01,640] ERROR in app: Exception on /evaluate_responses [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 201, in evaluate_responses\n",
      "    average_score, summary = evaluate_feedback(feedback_list)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 148, in evaluate_feedback\n",
      "    score = extract_score(feedback)  # פונקציה שתשאב את הציון מהפידבק\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_11884\\182820701.py\", line 185, in extract_score\n",
      "    score = feedback_json.get(\"score\", 0)  # קבלת הערך של \"score\" או 0 אם הוא לא קיים\n",
      "            ^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'list' object has no attribute 'get'\n",
      "127.0.0.1 - - [25/Mar/2025 16:37:01] \"POST /evaluate_responses HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [25/Mar/2025 16:37:03] \"POST /check_answer HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import base64\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "#gemini_api_key = os.getenv('GEMINI_API_KEY', 'AIzaSyA1_-pRQQz89muAzUCFH1AFPDxyNkG5ctI')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def encode_file_to_base64(file_path):\n",
    "    \"\"\" ממיר קובץ לבסיס 64 \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "def analyze_resume(resume_file_path):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    encoded_resume = encode_file_to_base64(resume_file_path)\n",
    "\n",
    "    prompt = \"שים לב לשאול שאלות שקשורות לידע שיש בקורות חיים נתח את קובץ קורות החיים המצורף וספק רשימה של 10 שאלות על הידיעות בחומר שיש בקורות חיים.\"\n",
    "   \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(\n",
    "                        mime_type=\"application/pdf\",\n",
    "                        data=encoded_resume,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=8192,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n",
    "def check_answer_with_gamini(question, answer):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    prompt = f\" האם התשובה לשאלה '{question}' נכונה? התשובה היא: '{answer}'.\"\n",
    "    \n",
    "    # הוספת הנחיות לקבלת תשובה נכונה במקרה שהתשובה לא נכונה\n",
    "    prompt += \" אם התשובה לא נכונה, אנא ספק את התשובה הנכונה. תן לי ציון על התשובה בין 0 ל-10, כאשר 10 זה תשובה נכונה לחלוטין.\"\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "\n",
    "import requests\n",
    "\n",
    "@app.route(\"/upload_resume\", methods=[\"POST\"])\n",
    "def upload_resume():\n",
    "    data = request.get_json()\n",
    "    file_url = data.get(\"filePath\")\n",
    "\n",
    "    if not file_url:\n",
    "        return jsonify({\"error\": \"Invalid or missing file path\"}), 400\n",
    "\n",
    "    try:\n",
    "        # הורדת הקובץ מ-S3\n",
    "        response = requests.get(file_url)\n",
    "        if response.status_code != 200:\n",
    "            return jsonify({\"error\": \"Failed to download the file from S3\"}), 400\n",
    "\n",
    "        temp_path = \"temp_resume.pdf\"\n",
    "        with open(temp_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        analysis_result = analyze_resume(temp_path)\n",
    "        questions = analysis_result.split(\"\\n\")\n",
    "        \n",
    "        return jsonify({\"questions\": questions}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "    finally:\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "\n",
    "@app.route(\"/check_answer\", methods=[\"POST\"])\n",
    "def check_answer():\n",
    "    data = request.json\n",
    "    question = data.get('question')\n",
    "    answer = data.get('answer')\n",
    "    \n",
    "    if not question or not answer:\n",
    "        return jsonify({\"error\": \"Question and answer must be provided\"}), 400\n",
    "\n",
    "    feedback = check_answer_with_gamini(question, answer)\n",
    "    \n",
    "    return jsonify({\"feedback\": feedback}), 200\n",
    "def evaluate_feedback(feedback_list):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    total_score = 0\n",
    "    total_feedback = len(feedback_list)\n",
    "\n",
    "    for feedback in feedback_list:\n",
    "        # נניח שהפידבק הוא טקסט כמו \"תשובה נכונה. ציון: 10\" או \"תשובה לא נכונה. ציון: 4. התשובה הנכונה היא: 'תשובה נכונה'.\"\n",
    "        score = extract_score(feedback)  # פונקציה שתשאב את הציון מהפידבק\n",
    "        total_score += score\n",
    "\n",
    "    average_score = total_score / total_feedback if total_feedback > 0 else 0\n",
    "\n",
    "    # סיכום על הביצועים\n",
    "    summary_prompt = f\"בהתבסס על הציונים והמשובים הבאים: {feedback_list}, מה המסקנות לגבי הביצועים של הנבחן? במה הוא טוב ובמה עליו לשפר?\"\n",
    "    \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=summary_prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    summary_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        summary_text += chunk.text\n",
    "\n",
    "    return average_score, summary_text\n",
    "\n",
    "def extract_score(feedback):\n",
    "    import re\n",
    "    print(\"Feedback received:\", feedback)  # הדפסת הפידבק לבדיקה\n",
    "    match = re.search(r'ציון:\\s*(\\d+(\\.\\d+)?)', feedback)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    print(\"Failed to extract score, returning 0\")  # אם אין התאמה, נדע זאת\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "@app.route(\"/evaluate_responses\", methods=[\"POST\"])\n",
    "def evaluate_responses():\n",
    "    data = request.json\n",
    "    feedback_list = data.get('feedback_list', [])\n",
    "    \n",
    "    if not feedback_list:\n",
    "        return jsonify({\"error\": \"Feedback list must be provided\"}), 400\n",
    "\n",
    "    average_score, summary = evaluate_feedback(feedback_list)\n",
    "    \n",
    "    return jsonify({\"average_score\": average_score, \"summary\": summary}), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
