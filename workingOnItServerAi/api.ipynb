{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.100:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [22/Mar/2025 21:20:31] \"OPTIONS /upload_resume HTTP/1.1\" 200 -\n",
      "[2025-03-22 21:20:32,884] ERROR in app: Exception on /upload_resume [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_26964\\1032977715.py\", line 140, in upload_resume\n",
      "    if os.path.exists(temp_path):\n",
      "                      ^^^^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'temp_path' where it is not associated with a value\n",
      "127.0.0.1 - - [22/Mar/2025 21:20:32] \"POST /upload_resume HTTP/1.1\" 500 -\n",
      "[2025-03-22 21:20:34,306] ERROR in app: Exception on /upload_resume [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_26964\\1032977715.py\", line 140, in upload_resume\n",
      "    if os.path.exists(temp_path):\n",
      "                      ^^^^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'temp_path' where it is not associated with a value\n",
      "127.0.0.1 - - [22/Mar/2025 21:20:34] \"POST /upload_resume HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:21:52] \"OPTIONS /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:21:57] \"POST /upload_resume HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:31] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:33] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:35] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:40] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:44] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:46] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:47] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:49] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:52] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:52] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:55] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:22:57] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:04] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:06] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:09] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:14] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:16] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:19] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:20] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:22] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:24] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:25] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:26] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:28] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:32] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:34] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:37] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:38] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:38] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:41] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:41] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:44] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:47] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:50] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "[2025-03-22 21:23:51,534] ERROR in app: Exception on /check_answer [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 919, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask_cors\\extension.py\", line 176, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_26964\\1032977715.py\", line 153, in check_answer\n",
      "    feedback = check_answer_with_gamini(question, answer)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_26964\\1032977715.py\", line 89, in check_answer_with_gamini\n",
      "    for chunk in client.models.generate_content_stream(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 5507, in generate_content_stream\n",
      "    for chunk in response:\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\models.py\", line 4409, in _generate_content_stream\n",
      "    for response_dict in self._api_client.request_streamed(\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 659, in request_streamed\n",
      "    session_response = self._request(http_request, stream=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 557, in _request\n",
      "    errors.APIError.raise_for_response(response)\n",
      "  File \"c:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\genai\\errors.py\", line 106, in raise_for_response\n",
      "    raise ClientError(status_code, response)\n",
      "google.genai.errors.ClientError: 429 Too Many Requests. {'message': 'Response not read', 'status': 'Too Many Requests'}\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:51] \"POST /check_answer HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:56] \"OPTIONS /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:23:59] \"POST /check_answer HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Mar/2025 21:24:00] \"POST /check_answer HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import base64\n",
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "load_dotenv()\n",
    "#gemini_api_key = os.getenv('GEMINI_API_KEY', 'AIzaSyA1_-pRQQz89muAzUCFH1AFPDxyNkG5ctI')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def encode_file_to_base64(file_path):\n",
    "    \"\"\" ממיר קובץ לבסיס 64 \"\"\"\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "def analyze_resume(resume_file_path):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    encoded_resume = encode_file_to_base64(resume_file_path)\n",
    "\n",
    "    prompt = \"נתח את קובץ קורות החיים המצורף וספק רשימה של 10 שאלות על הידיעות בחומר שיש בקורות חיים.\"\n",
    "   \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(\n",
    "                        mime_type=\"application/pdf\",\n",
    "                        data=encoded_resume,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=8192,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n",
    "def check_answer_with_gamini(question, answer):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    prompt = f\" האם התשובה לשאלה '{question}' נכונה? התשובה היא: '{answer}'.\"\n",
    "    \n",
    "    # הוספת הנחיות לקבלת תשובה נכונה במקרה שהתשובה לא נכונה\n",
    "    prompt += \" אם התשובה לא נכונה, אנא ספק את התשובה הנכונה. תן לי ציון על התשובה בין 0 ל-10, כאשר 10 זה תשובה נכונה לחלוטין.\"\n",
    "\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    response_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        response_text += chunk.text\n",
    "\n",
    "    return response_text\n",
    "# @app.route(\"/upload_resume\", methods=[\"POST\"])\n",
    "# def upload_resume():\n",
    "#     if \"resume\" not in request.files:\n",
    "#         return jsonify({\"error\": \"No resume file provided\"}), 400\n",
    "   \n",
    "#     resume_file = request.files[\"resume\"]\n",
    "#     temp_path = \"temp_resume.pdf\"\n",
    "#     resume_file.save(temp_path)\n",
    "   \n",
    "#     try:\n",
    "#         analysis_result = analyze_resume(temp_path)\n",
    "#         questions = analysis_result.split('\\n')  # נניח שהשאלות מופרדות על ידי קווים\n",
    "        \n",
    "#         return jsonify({\"questions\": questions}), 200  # מחזירים רשימה\n",
    "#     except Exception as e:\n",
    "#         return jsonify({\"error\": str(e)}), 500\n",
    "#     finally:\n",
    "#         os.remove(temp_path)\n",
    "import requests\n",
    "\n",
    "@app.route(\"/upload_resume\", methods=[\"POST\"])\n",
    "def upload_resume():\n",
    "    data = request.get_json()\n",
    "    file_url = data.get(\"filePath\")\n",
    "\n",
    "    if not file_url:\n",
    "        return jsonify({\"error\": \"Invalid or missing file path\"}), 400\n",
    "\n",
    "    try:\n",
    "        # הורדת הקובץ מ-S3\n",
    "        response = requests.get(file_url)\n",
    "        if response.status_code != 200:\n",
    "            return jsonify({\"error\": \"Failed to download the file from S3\"}), 400\n",
    "\n",
    "        temp_path = \"temp_resume.pdf\"\n",
    "        with open(temp_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        analysis_result = analyze_resume(temp_path)\n",
    "        questions = analysis_result.split(\"\\n\")\n",
    "        \n",
    "        return jsonify({\"questions\": questions}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "    finally:\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "\n",
    "@app.route(\"/check_answer\", methods=[\"POST\"])\n",
    "def check_answer():\n",
    "    data = request.json\n",
    "    question = data.get('question')\n",
    "    answer = data.get('answer')\n",
    "    \n",
    "    if not question or not answer:\n",
    "        return jsonify({\"error\": \"Question and answer must be provided\"}), 400\n",
    "\n",
    "    feedback = check_answer_with_gamini(question, answer)\n",
    "    \n",
    "    return jsonify({\"feedback\": feedback}), 200\n",
    "def evaluate_feedback(feedback_list):\n",
    "    client = genai.Client(api_key=gemini_api_key)\n",
    "    model = \"gemini-2.0-flash\"  # ודא שהמודל קיים\n",
    "\n",
    "    total_score = 0\n",
    "    total_feedback = len(feedback_list)\n",
    "\n",
    "    for feedback in feedback_list:\n",
    "        # נניח שהפידבק הוא טקסט כמו \"תשובה נכונה. ציון: 10\" או \"תשובה לא נכונה. ציון: 4. התשובה הנכונה היא: 'תשובה נכונה'.\"\n",
    "        score = extract_score(feedback)  # פונקציה שתשאב את הציון מהפידבק\n",
    "        total_score += score\n",
    "\n",
    "    average_score = total_score / total_feedback if total_feedback > 0 else 0\n",
    "\n",
    "    # סיכום על הביצועים\n",
    "    summary_prompt = f\"בהתבסס על הציונים והמשובים הבאים: {feedback_list}, מה המסקנות לגבי הביצועים של הנבחן? במה הוא טוב ובמה עליו לשפר?\"\n",
    "    \n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=summary_prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=512,\n",
    "        response_mime_type=\"application/json\",\n",
    "    )\n",
    "\n",
    "    summary_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model, contents=contents, config=generate_content_config\n",
    "    ):\n",
    "        summary_text += chunk.text\n",
    "\n",
    "    return average_score, summary_text\n",
    "\n",
    "def extract_score(feedback):\n",
    "    import re\n",
    "    match = re.search(r'ציון:\\s*(\\d+(\\.\\d+)?)', feedback)\n",
    "    return float(match.group(1)) if match else 0.0\n",
    "\n",
    "@app.route(\"/evaluate_responses\", methods=[\"POST\"])\n",
    "def evaluate_responses():\n",
    "    data = request.json\n",
    "    feedback_list = data.get('feedback_list', [])\n",
    "    \n",
    "    if not feedback_list:\n",
    "        return jsonify({\"error\": \"Feedback list must be provided\"}), 400\n",
    "\n",
    "    average_score, summary = evaluate_feedback(feedback_list)\n",
    "    \n",
    "    return jsonify({\"average_score\": average_score, \"summary\": summary}), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
